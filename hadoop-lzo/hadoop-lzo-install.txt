#ubuntu
apt-get install liblzo2-dev
#centos
yum install lzo liblzo-devel

# 下载
wget http://www.oberhumer.com/opensource/lzo/download/lzo-2.06.tar.gz
# 解压
tar -zxvf lzo-2.06.tar.gz
# 进入目录
cd lzo-2.06
# export
export CFLAGS=-m64
# 指定编译之后的位置   报错configure: error: ACC conformance test failed. Stop. 添加参数CPPFLAGS="$CPPFLAGS -std=c90 -fPIC"
./configure -enable-shared -prefix=/usr/local/hadoop/lzo/
# 开始编译安装
make && sudo make install

#
# 下载
wget https://github.com/twitter/hadoop-lzo/archive/refs/tags/release-0.4.20.tar.gz
# 解压后的文件夹名为hadoop-lzo-master
unzip master.zip
# 然后进入hadoop-lzo-master目录，依次执行下面的命令
cd hadoop-lzo-master

export CFLAGS=-m64
export CXXFLAGS=-m64
export C_INCLUDE_PATH=/usr/local/hadoop/lzo/include
export LIBRARY_PATH=/usr/local/hadoop/lzo/lib

mvn clean package -Dmaven.test.skip=true

cd target/native/Linux-amd64-64

# 会在~目录下生成几个文件
tar -cBf - -C lib . | tar -xBvf - -C ~

cp ~/libgplcompression* $HADOOP_HOME/lib/native/

# 需要把hadoop-lzo-0.4.21-SNAPSHOT.jar 复制到hadoop中
cp target/hadoop-lzo-0.4.21-SNAPSHOT.jar $HADOOP_HOME/share/hadoop/common/
cp target/hadoop-lzo-0.4.21-SNAPSHOT.jar $HADOOP_HOME/share/hadoop/mapreduce/lib

# 最后别忘记将下面三个地址的文件复制到其他节点
 $HADOOP_HOME/lib/native/libgplcompression*
 $HADOOP_HOME/share/hadoop/mapreduce/lib/hadoop-lzo-0.4.21-SNAPSHOT.jar
 $HADOOP_HOME/share/hadoop/common/hadoop-lzo-0.4.21-SNAPSHOT.jar
 
 
 #$HADOOP_HOME/etc/hadoop/hadoop-env.sh 
 export LD_LIBRARY_PATH=/usr/local/hadoop/lzo/lib
export HADOOP_CLASSPATH="<extra_entries>:$HADOOP_CLASSPATH:${HADOOP_HOME}/share/hadoop/common"
export JAVA_LIBRARY_PATH=${JAVA_LIBRARY_PATH}:${HADOOP_HOME}/lib/native

#$HADOOP_HOME/etc/hadoop/core-site.xml
<property>
    <name>io.compression.codecs</name>
    <value>org.apache.hadoop.io.compress.GzipCodec,
           org.apache.hadoop.io.compress.DefaultCodec,
           com.hadoop.compression.lzo.LzoCodec,
           com.hadoop.compression.lzo.LzopCodec,
           org.apache.hadoop.io.compress.BZip2Codec
        </value>
</property>

<property>
    <name>io.compression.codec.lzo.class</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
</property>

#
<property>
    <name>mapred.compress.map.output</name>
    <value>true</value>
</property>

<property>
    <name>mapred.map.output.compression.codec</name>
    <value>com.hadoop.compression.lzo.LzoCodec</value>
</property>

<property>
    <name>mapred.child.env</name>
    <value>LD_LIBRARY_PATH=/usr/local/hadoop/lzo/lib</value>
</property>

<property>
    <name>mapreduce.map.env </name>
    <value>LD_LIBRARY_PATH=/usr/local/hadoop/lzo/lib</value>
</property>

<property>
    <name>mapreduce.reduce.env </name>
    <value>LD_LIBRARY_PATH=/usr/local/hadoop/lzo/lib</value>
</property>


#spark-env.sh
export SPARK_LIBRARY_PATH=$SPARK_LIBRARY_PATH:/usr/local/hadoop/lzo/lib
export SPARK_CLASSPATH=$SPARK_CLASSPATH:/path/to/your/hadoop-lzo/java/libs
