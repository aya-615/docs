export FLINK_HOME=flink-1.11.3
export HADOOP_HOME=CDH-5.14.0
export HADOOP_CLASSPATH=`$HADOOP_HOME/bin/hadoop classpath`
export CLASSPATH=$FLINK_HOME/lib:$CLASSPATH
export PATH=$FLINK_HOME/bin:$PATH

#
./bin/sql-client.sh embedded -j $FLINK_HOME/lib/iceberg-flink-runtime-0.11.1.jar shell

$FLINK_HOME/bin/sql-client.sh embedded -j iceberg/iceberg-flink-runtime-0.11.1.jar shell


#
CREATE CATALOG hadoop_catalog WITH (
  'type'='iceberg',
  'catalog-type'='hadoop',
  'warehouse'='hdfs://xxx/user/xxx/dw',
  'property-version'='1'
);
CREATE DATABASE hadoop_catalog.iceberg_db;
USE hadoop_catalog.iceberg_db;

CREATE TABLE hadoop_catalog.iceberg_db.sample (
    id BIGINT COMMENT 'unique id',
    data STRING
);

CREATE DATABASE hadoop_catalog.iceberg_db;
USE hadoop_catalog.iceberg_db;

CREATE TABLE hadoop_catalog.iceberg_db.sample (
    id BIGINT COMMENT 'unique id',
    data STRING
);


CREATE TABLE hadoop_catalog.iceberg_db.sample_pt (
    id BIGINT COMMENT 'unique id',
    data STRING
) PARTITIONED BY (data);

CREATE TABLE  hadoop_catalog.iceberg_db.sample_like LIKE hadoop_catalog.iceberg_db.sample;

ALTER TABLE hadoop_catalog.iceberg_db.sample SET ('write.format.default'='avro')

#java.lang.UnsupportedOperationException: Cannot rename Hadoop tables
ALTER TABLE hadoop_catalog.iceberg_db.sample RENAME TO hadoop_catalog.iceberg_db.new_sample;

DROP TABLE hadoop_catalog.iceberg_db.sample;


#dependency jar  
orc-core-1.6.8.jar
parquet-column-1.12.0.jar
iceberg-flink-runtime-0.11.1.jar

